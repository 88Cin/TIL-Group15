{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d219c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "964c7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to export the center point, velocity and acceleration of the vehicles in dataset\n",
    "#Define the number of exports with inputs\n",
    "def load_single_data(i):    \n",
    "    data = zarr.open('H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\CarFollowing/trainHA.zarr', mode='a')\n",
    "    start, end = data.index_range[i]\n",
    "    # get timestamps\n",
    "    timestamps = data.timestamp[start:end]\n",
    "    # get position, speed, and acceleration\n",
    "    x_lead = data.lead_centroid[start:end]\n",
    "    v_lead = data.lead_velocity[start:end]\n",
    "    a_lead = data.lead_acceleration[start:end]\n",
    "    id=np.ones((1,x_lead.shape[0]))*i\n",
    "    x_follow = data.follow_centroid[start:end]\n",
    "    v_follow = data.follow_velocity[start:end]\n",
    "    a_follow = data.follow_acceleration[start:end]\n",
    "    array = np.vstack((id, x_lead, v_lead, a_lead, x_follow, v_follow, a_follow, timestamps))\n",
    "    return array.T\n",
    "#Define a function to export the size of the vehicles in dataset\n",
    "def load_size(i):\n",
    "    data = zarr.open('H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\CarFollowing/trainHA.zarr', mode='a')\n",
    "    size_lead = 4.85 # this is the size of the lead vehicles，for HA there's only one size\n",
    "    size_follow = data.follow_size[i] # this is the size of the follow vehicles\n",
    "    id=np.ones(1)*i # ID\n",
    "    array = np.vstack((id, size_lead, size_follow)) \n",
    "    return array.T\n",
    "#Organize all data into a csv file\n",
    "def load_multi_size(i):\n",
    "    multi_data = None\n",
    "    for x in range(i + 1):\n",
    "        single_data1 = load_size(x)\n",
    "        if x == 0:\n",
    "            multi_data = single_data1\n",
    "        else:\n",
    "            multi_data = np.vstack([multi_data, single_data1])\n",
    "    return multi_data\n",
    "def load_multi_data(i):\n",
    "    multi_data = None\n",
    "    for x in range(i+1):\n",
    "        single_data = load_single_data(x)\n",
    "        if x == 0:\n",
    "            multi_data = single_data\n",
    "        else:\n",
    "            multi_data = np.vstack([multi_data, single_data])\n",
    "    return multi_data\n",
    "#Define the number of exports with inputs\n",
    "p=int(input('type in the number you want'))\n",
    "np.savetxt( \"H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HA/multi_data.csv\", load_multi_data(p), delimiter=\",\" )\n",
    "np.savetxt( \"H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HA/multi_size.csv\", load_multi_size(p), delimiter=\",\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b0c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.loadtxt('H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HA/multi_data.csv',delimiter=\",\" )\n",
    "data_size=np.loadtxt('H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HA/multi_size.csv',delimiter=\",\" )\n",
    "#data_size.columns = [\"ID\", \"size_lead\", \"size_follow\"]\n",
    "#data.columns = [\"ID\",\"x_lead\", \"v_lead\", \"a_lead\", \"x_follow\", \"v_follow\", \"a_follow\", \"timestamps\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95961011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define A_distance as the vehicle distance (tail of lead vehicle to head of follow vehicle)\n",
    "# Define B_distance is the vehicle distance (head of lead vehicle to head of follow vehicle)\n",
    "\n",
    "def distance(x):\n",
    "    x_data=np.squeeze(data[np.where(data[:,0]==x),:],0)\n",
    "    x_size=np.squeeze(data_size[np.where(data_size[:,0]==x),:],0)\n",
    "    x_lead=x_data[:,1]\n",
    "    x_follow=x_data[:,4]\n",
    "    size_lead = x_size[:,1]\n",
    "    size_follow = x_size[:,2]\n",
    "    id=np.ones(1)*x\n",
    "    A_distance=[]\n",
    "    B_distance=[]\n",
    "    for y in range(1,x_lead.size):\n",
    "        A = x_lead[y] - x_follow[y] - 0.5 * (size_lead[0] + size_follow[0])# A_distance\n",
    "        B = x_lead[y] - x_follow[y] - 0.5 * (size_follow[0] - size_lead[0])# A_distance\n",
    "        A_distance.append(A)\n",
    "        B_distance.append(B)\n",
    "    id_tiled = np.tile(id, len(A_distance))\n",
    "    array = np.vstack((id_tiled, A_distance, B_distance))\n",
    "    return array\n",
    "def load_multi_distance(i):    \n",
    "    multi_data = None\n",
    "    for x in range(i+1):\n",
    "        single_data = distance(x).T\n",
    "        if x == 0:\n",
    "            multi_data = single_data\n",
    "        else:\n",
    "            multi_data = np.vstack([multi_data, single_data])\n",
    "    return multi_data\n",
    "def write_to_csv(data, filename=\"H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HA/distance.csv\"):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(data)\n",
    "data_to_save = load_multi_distance(p)\n",
    "write_to_csv(data_to_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a32b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_13100\\3130674205.py:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  data3 = np.genfromtxt('H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HA/regimes_list_HA_train.csv', delimiter=',',  dtype=None, names=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mh:\\Desktop\\Q1\\python\\project\\TIL-Group15\\files\\src\\project_model.ipynb 单元格 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Desktop/Q1/python/project/TIL-Group15/files/src/project_model.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m pattern_data \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Desktop/Q1/python/project/TIL-Group15/files/src/project_model.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m start_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/Desktop/Q1/python/project/TIL-Group15/files/src/project_model.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m pattern, time \u001b[39min\u001b[39;00m pattern_times\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Desktop/Q1/python/project/TIL-Group15/files/src/project_model.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mif\u001b[39;00m pattern \u001b[39m==\u001b[39m pattern_name: \n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/Desktop/Q1/python/project/TIL-Group15/files/src/project_model.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         length \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(time \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(all_data) \u001b[39m/\u001b[39m \u001b[39msum\u001b[39m(pattern_times\u001b[39m.\u001b[39mvalues()))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data3 = np.genfromtxt('H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HA/regimes_list_HA_train.csv', delimiter=',',  dtype=None, names=True)\n",
    "# define the list of regimes\n",
    "pattern = re.compile(r'Fa|Fd|A|D|F|C|S')\n",
    "output_list = []  # the list to store the data\n",
    "for row in data3:\n",
    "    regime = row['regime_comb'].decode('utf-8')\n",
    "    matches = pattern.findall(regime)  # use re to cut regime_comb\n",
    "    row_dict = {}  \n",
    "    for module in matches:\n",
    "        row_dict[module] = row[module]\n",
    "    \n",
    "    # export the data into the list\n",
    "    output_list.append(row_dict)\n",
    "data = np.loadtxt('H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HA/multi_data.csv', delimiter=\",\")\n",
    "\n",
    "patterns = [\"A\", \"D\", \"F\", \"Fa\", \"Fd\", \"C\", \"S\"]  # the list of regimes\n",
    "\n",
    "# make a CSV file for each regime\n",
    "for pattern_name in patterns:\n",
    "    with open(f'H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HA/{pattern_name}.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # write in the title for each line\n",
    "        writer.writerow(['id', 'x_lead', 'v_lead', 'a_lead', 'x_follow', 'v_follow', 'a_follow', 'timestamps'])\n",
    "\n",
    "        for i in range(len(output_list)):\n",
    "            pattern_times = output_list[i]\n",
    "            all_data = data[data[:, 0] == i, 1:]  # load the data except ID\n",
    "            pattern_data = {}\n",
    "            start_index = 0\n",
    "            for pattern, time in pattern_times.items():\n",
    "                if pattern == pattern_name: \n",
    "                    length = int(time * len(all_data) / sum(pattern_times.values()))\n",
    "                    pattern_data[pattern] = all_data[start_index:start_index+length]\n",
    "                    start_index += length\n",
    "\n",
    "            # save the result in CSV file\n",
    "            for _, pattern_specific_data in pattern_data.items():\n",
    "                for row_data in pattern_specific_data:\n",
    "                    writer.writerow([i] + list(row_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fb5017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 从CSV文件中读取数据\n",
    "regimes_list_path = 'H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HH/regimes_list_HH_train.csv'\n",
    "data = np.loadtxt(regimes_list_path, delimiter=\",\",skiprows=1, dtype=object)\n",
    "\n",
    "multi_data_path = 'H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HH/multi_data.csv'\n",
    "multi_data = np.loadtxt(multi_data_path, delimiter=\",\",skiprows=1, dtype=object)\n",
    "\n",
    "# 定义一个函数来计算regime的数量（排除ADF）\n",
    "def count_regimes_except_adf(regime_str):\n",
    "    count = len([r for r in regime_str.split('ADF') if r]) - 1\n",
    "    return max(0, count)\n",
    "\n",
    "# 根据类别分类数据\n",
    "categories = {\n",
    "    \"ADF\": [],\n",
    "    \"ADF+1\": [],\n",
    "    \"ADF+2\": [],\n",
    "    \"ADF+3\": []\n",
    "}\n",
    "\n",
    "for row in data:\n",
    "    regime_comb = row[5]\n",
    "    regime_id = float(row[0])  # Assuming the ID is in the first column and is a float\n",
    "    if 'ADF' in regime_comb:\n",
    "        regime_count = count_regimes_except_adf(regime_comb)\n",
    "        key = f'ADF+{regime_count}' if regime_count else 'ADF'\n",
    "        categories[key].append(regime_id)\n",
    "\n",
    "# 从multi_data中筛选数据，并保存到不同的CSV文件\n",
    "for key, ids in categories.items():\n",
    "    filtered_data = [row for row in multi_data if float(row[0]) in ids]  # Assuming the ID is in the first column of multi_data and is a float\n",
    "    output_path = f'H:\\Desktop\\Q1\\python\\project\\TIL-Group15\\dataset\\split_data\\HH/{key}_multi_data.csv'\n",
    "    np.savetxt(output_path, filtered_data, delimiter=\",\", fmt='%s')  # using %s to save as string, adjust if necessary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('TIL6022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "235118494f6096765c1deb9d143943fcb560fd7b79d70fb1cbb738bbc852222c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
